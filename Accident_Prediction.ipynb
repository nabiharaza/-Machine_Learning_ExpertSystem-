{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nabiharaza/-Machine_Learning_ExpertSystem-/blob/master/Accident_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htZtOC7LGqcO"
   },
   "source": [
    "# CSCI-639 Accident Prediction\n",
    "#### **Authors-  Nabiha Raza, Neel Kirit**\n",
    "\n",
    "## Papers Referred - \n",
    "* Blah Blah\n",
    "\n",
    "## Design Overview -\n",
    "* Some shit\n",
    "\n",
    "## Model overview -\n",
    "* Fouck you\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvmCXsu9HPHj"
   },
   "source": [
    "## Step 1\n",
    "We import all necceary libs we have used in our Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nB0h8TMpI__u",
    "outputId": "82113d95-9511-49d8-8cd5-a4d1f1fa7a0f"
   },
   "outputs": [],
   "source": [
    "#https://www.notion.so/Crash-1500-bd45c6772b10436592241544b027d356\n",
    "#https://drive.google.com/drive/folders/0APfpY9WB1JnvUk9PVA\n",
    "\n",
    "\n",
    "# Import all the libs \n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import timeit\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from skimage import transform\n",
    "import skimage\n",
    "from skimage import io\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split   ### import sklearn tool\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Input, TimeDistributed\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctTTFrqnHgRw"
   },
   "source": [
    "## Step 2\n",
    "Mount Google Drive to load 1500 videos for training / tesing \n",
    "\n",
    "**For Grader** <br>\n",
    "Please click on the URL below and authorize your google drive, then point to the directory where you have kept 1500 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4NfHjbHQB4vc",
    "outputId": "fe8d6141-bcf6-4cbc-fe6d-3bef0fab61c1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCj1xKR8IDTU"
   },
   "source": [
    "## Step 3\n",
    "Load the dataset by reading the videos and extracting the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIATpAMLALsm"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path_to_video, total_frames):\n",
    "    # Capture a video\n",
    "    vidcap = cv2.VideoCapture(path_to_video)\n",
    "    # Check if video frame is read correctly\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    img = []\n",
    "    # Read all frames of video iteratively\n",
    "    while success:    \n",
    "        success,image = vidcap.read()\n",
    "        tmp = skimage.color.rgb2gray(np.array(image))\n",
    "        img.append(tmp)\n",
    "        count += 1\n",
    "        if count == total_frames:\n",
    "            break\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64yhPQmOWPVv"
   },
   "source": [
    "## Step 4\n",
    "Read the `1500.txt` file and start loading the dataset\n",
    "Spit out the # of videos that will be used out for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "vDIBID0GFsfZ",
    "outputId": "dc86b455-92ec-49be-d114-44194ae8f79f"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "all_frames = []\n",
    "f = open(\"Annotations.txt\", \"r\")\n",
    "lines = f.readlines()\n",
    "for line in lines[1:10]:\n",
    "    video_name = line[0:6]\n",
    "    y_labels = line[10:156].split(',')\n",
    "    y_labels = [int(i[1]) for i in y_labels ]\n",
    "    total_frames = len(y_labels)\n",
    "    \n",
    "    x1 = line[159:].split(',')[2]\n",
    "    x2 = line[159:].split(',')[3]\n",
    "    is_ego = line[159:].split(',')[4]\n",
    "    if \"Yes\" in is_ego:\n",
    "        frame_count = 0\n",
    "        for i in y_labels:\n",
    "          frame_count += 1\n",
    "          if i == 1:\n",
    "              break\n",
    "        flag = 0\n",
    "        for i in y_labels:\n",
    "            if i == 1 and flag == 0:\n",
    "\n",
    "              break\n",
    "        for i in range(len(y_labels)):\n",
    "          if y_labels[i] != 1:\n",
    "              y_labels[i] = frame_count\n",
    "              frame_count -= 1\n",
    "          else:\n",
    "              break\n",
    "                \n",
    "        labels.extend(y_labels)\n",
    "        img = load_dataset(\"Crash1500/\"+video_name+\".mp4\", total_frames)\n",
    "        all_frames.extend(img)\n",
    "# Check if all videos' frame are loaded in np array\n",
    "print(\"# of videos loaded\",len(all_frames))\n",
    "print(\"# of labels\", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpPeNRgtUocK"
   },
   "source": [
    "## Step 5\n",
    "Split the data into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ign92kwpcHC6"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AzHxFRzWCa2"
   },
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "# all_frames = np.array(all_frames)\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_frames, labels, test_size=0.40, random_state=0)  ### split\n",
    "# print(x_train)\n",
    "\n",
    "print(len(x_train), len(y_train))\n",
    "print(len(x_test), len(y_test))\n",
    "\n",
    "r = np.array(x_train[0])\n",
    "g = np.array(x_train[1])\n",
    "b = np.array(x_train[2])\n",
    "x_train = np.dstack((r,g,b))\n",
    "print(x_train.shape)\n",
    "\n",
    "r = np.array(x_test[0])\n",
    "g = np.array(x_test[1])\n",
    "b = np.array(x_test[2])\n",
    "x_test = np.dstack((r,g,b))\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgXot2lFNiMn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "apLJ1hFEVwcP",
    "outputId": "10f3f115-fd4b-4719-d6f9-ecfe3e62274f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-5a2c0c1b0407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, implementation, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m                                    \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m                                    \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m                                    **kwargs)\n\u001b[0m\u001b[1;32m   2239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivity_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m                              \u001b[0;34m'(tuple of integers, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                              'one integer per RNN state).')\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 batch_input_shape = (\n\u001b[0;32m--> 163\u001b[0;31m                     batch_size,) + tuple(kwargs['input_shape'])\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m       raise TypeError(\n\u001b[0;32m--> 570\u001b[0;31m           \"Cannot iterate over a tensor with unknown first dimension.\")\n\u001b[0m\u001b[1;32m    571\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_TensorIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot iterate over a tensor with unknown first dimension."
     ]
    }
   ],
   "source": [
    "### set hyper-parameters\n",
    "batch_size = 15\n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "\n",
    "### number of hidden layers in each NN\n",
    "row_hidden = 128\n",
    "col_hidden = 128\n",
    "\n",
    "### get shape of rows/columns for each image\n",
    "frame, row, col = (9, 720, 1280)\n",
    "\n",
    "### 4D input - for each 3-D sequence (of 2-D image) in each video (4th)\n",
    "x = Input(shape=(frame, row, col))\n",
    "\n",
    "encoded_rows = TimeDistributed(LSTM(row_hidden))(x)  ### encodes row of pixels using TimeDistributed Wrapper\n",
    "encoded_columns = LSTM(col_hidden)(encoded_rows)     ### encodes columns of encoded rows using previous layer\n",
    "\n",
    "### set up prediction and compile the model\n",
    "prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n",
    "model = Model(x, prediction)\n",
    "model.compile(loss='categorical_crossentropy', ### loss choice for category classification - computes probability error\n",
    "              optimizer='NAdam',               ### NAdam optimization\n",
    "              metrics=['accuracy'])    \n",
    "# model.fit(x_train, y_train,                            ### fit training data\n",
    "#                   batch_size=len(x_train),                ### reiterate batch size - in this case we already set up the batches\n",
    "#                   epochs=100,                          ### number of times to run through each batch\n",
    "#                   validation_data=(x_test, y_test))  \n",
    "\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(4, input_shape=(1280, 1)))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Accident_Prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
